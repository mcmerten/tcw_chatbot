{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.prompts import PromptTemplate#\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, RetrievalQA\n",
    "from langchain import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_TOKEN')\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma(persist_directory=\"db\", embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in German:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=db.as_retriever(),\n",
    "                                 chain_type_kwargs=chain_type_kwargs, \n",
    "                                 return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query)\n",
    "qa_rerank = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"map_rerank\", metadata_keys=['source'], return_intermediate_steps=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Wann hat Prof. Dr. Wildemann einen Verdiensorden erhalten?\"\n",
    "result = qa_rerank({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'scraper/html/tcw.de/tcw.de_sitemap.html',\n",
       " 'intermediate_steps': [{'answer': ' Ich weiß es nicht.', 'score': '0'},\n",
       "  {'answer': ' TCW bietet Beratungsdienstleistungen, Finanzdienstleistungen und Immobiliendienstleistungen an.',\n",
       "   'score': '100'},\n",
       "  {'answer': ' TCW bietet Unternehmensberatung an.', 'score': '100'},\n",
       "  {'answer': ' TCW bietet Beratungsdienstleistungen in den Bereichen Finanzen, Steuern, Recht und Unternehmensführung an.',\n",
       "   'score': '100'}],\n",
       " 'output_text': ' TCW bietet Beratungsdienstleistungen, Finanzdienstleistungen und Immobiliendienstleistungen an.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "output_parser = RegexParser(\n",
    "    regex=r\"(.*?)\\nScore: (.*)\",\n",
    "    output_keys=[\"answer\", \"score\"],\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "If the answer contains of multiple parts, give it in bullet points. \n",
    "\n",
    "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
    "\n",
    "Question: [question here]\n",
    "Helpful Answer In German: [answer here]\n",
    "Score: [score between 0 and 100]\n",
    "\n",
    "Begin!\n",
    "\n",
    "Context:\n",
    "---------\n",
    "{context}\n",
    "---------\n",
    "Question: {question}\n",
    "Helpful Answer In German:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    output_parser=output_parser,\n",
    ")\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"map_rerank\", metadata_keys=['source'], return_intermediate_steps=True, prompt=PROMPT)\n",
    "query = \"Welche Dienstleistungen bietet TCW an?\"\n",
    "result = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Wann hat Prof. Dr. Wildemann einen Verdiensorden erhalten?',\n",
       " 'result': ' 2006 erhielt Professor Wildemann vom Bayerischen MinisterprÃ¤sidenten den Bayerischen Verdienstorden fÃ¼r seine herausragenden Leistungen in Wissenschaft und Industrie.',\n",
       " 'source_documents': [Document(page_content='Staatsmedaille des Freistaates Bayern, das Bundesverdienstkreuz 1. Klasse der Bundesrepublik Deutschland und die EhrendoktorwÃ¼rden der UniversitÃ¤ten Klagenfurt, Passau und Cottbus verliehen. Seit 2004 ist er in die Logistik Hall of Fame aufgenommen worden. 2006 erhielt Professor Wildemann vom Bayerischen MinisterprÃ¤sidenten den Bayerischen Verdienstorden fÃ¼r seine herausragenden Leistungen in Wissenschaft und Industrie. Im Jahr 2008 wurde ihm die Ehrennadel der Bundesvereinigung Logistik', metadata={'source': 'scraper/html/tcw.de/tcw.de_unternehmen_sonstiges_prof-wildemann-4.html', 'filename': 'scraper/html/tcw.de/tcw.de_unternehmen_sonstiges_prof-wildemann-4.html', 'page_number': 1, 'category': 'NarrativeText'}),\n",
       "  Document(page_content='Prof. Wildemann', metadata={'source': 'scraper/html/tcw.de/tcw.de_sitemap.html', 'filename': 'scraper/html/tcw.de/tcw.de_sitemap.html', 'page_number': 1, 'category': 'ListItem'}),\n",
       "  Document(page_content='ordentlicher Professor fÃ¼r Betriebswirtschaftslehre an den UniversitÃ¤ten Bayreuth, Passau und seit 1989 an der Technischen UniversitÃ¤t MÃ¼nchen. Er hat Rufe an die UniversitÃ¤ten Stuttgart Hohenheim und Dortmund, an die Freie und die Technische UniversitÃ¤t Berlin, University of Southern California, Los Angeles, University of Indianapolis, Indianapolis, und an die Hochschule St. Gallen erhalten. Neben seiner LehrtÃ¤tigkeit steht Prof. Wildemann der Unternehmensberatung TCW Transfer-Centrum', metadata={'source': 'scraper/html/tcw.de/tcw.de_unternehmen_sonstiges_prof-wildemann-4.html', 'filename': 'scraper/html/tcw.de/tcw.de_unternehmen_sonstiges_prof-wildemann-4.html', 'page_number': 1, 'category': 'NarrativeText'}),\n",
       "  Document(page_content='Univ.-Prof. Dr. Dr. h. c. mult. Horst Wildemann', metadata={'source': 'scraper/html/tcw.de/tcw.de_unternehmen_sonstiges_prof-wildemann-4.html', 'filename': 'scraper/html/tcw.de/tcw.de_unternehmen_sonstiges_prof-wildemann-4.html', 'page_number': 1, 'category': 'Title'})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_query = \"Wann hat Prof. Dr. Wildemann einen Verdiensorden erhalten?\"\n",
    "\n",
    "qa({\"query\":input_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=db.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "query = \"Wo hat Prof. Dr. Wildemann studiert?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hat er in seiner Karriere Auszeichnungen erhalten?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Hat er in seiner Karriere Auszeichnungen erhalten?',\n",
       " 'chat_history': [('Wo hat Prof. Dr. Wildemann studiert?',\n",
       "   ' Prof. Dr. Wildemann hat in Aachen und Köln Maschinenbau (Dipl.-Ing.) und Betriebswirtschaftslehre (Dipl.-Kfm.) studiert.'),\n",
       "  ('Hat er in seiner Karriere Auszeichnungen erhalten?',\n",
       "   ' Yes, Prof. Dr. Wildemann has received awards in his career, including the prestigious German Research Foundation Prize.')],\n",
       " 'answer': ' Yes, Prof. Dr. Wildemann has received awards in his career, including the prestigious German Research Foundation Prize.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa_conv = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), db.as_retriever(), qa_prompt=PROMPT, chain_type=\"stuff\")\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"Wann kam Prof. Dr. Wildemann an die TU München?\"\n",
    "result = qa_conv({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))\n",
    "\n",
    "#query = \"Did he mention who she suceeded\"\n",
    "#result = qa_conv({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Wo hat Prof. Dr. Wildemann studiert?\"\n",
    "result = qa_conv({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hat er einen Vedienstorden erhalten?\"\n",
    "result = qa_conv({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Hat er einen Vedienstorden erhalten?',\n",
       " 'chat_history': [('Wann kam Prof. Dr. Wildemann an die TU München?', ' 1989'),\n",
       "  ('Wo hat Prof. Dr. Wildemann studiert?',\n",
       "   ' Er hat in Aachen und Köln Maschinenbau (Dipl.-Ing.) und Betriebswirtschaftslehre (Dipl.-Kfm.) studiert.'),\n",
       "  ('Hat er einen Vedienstorden erhalten?',\n",
       "   ' Ja, er hat 2006 vom Bayerischen Ministerpräsidenten den Bayerischen Verdienstorden erhalten.')],\n",
       " 'answer': ' Ja, er hat 2006 vom Bayerischen Ministerpräsidenten den Bayerischen Verdienstorden erhalten.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wann kam Prof. Dr. Wildemann an die TU München?', ' 1989'),\n",
       " ('Wo hat Prof. Dr. Wildemann studiert?',\n",
       "  ' Er hat in Aachen und Köln Maschinenbau (Dipl.-Ing.) und Betriebswirtschaftslehre (Dipl.-Kfm.) studiert.'),\n",
       " ('Hat er einen Vedienstorden erhalten?',\n",
       "  ' Ja, er hat 2006 vom Bayerischen Ministerpräsidenten den Bayerischen Verdienstorden erhalten.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"Did he mention who she suceeded\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qa_query(query):\n",
    "    result = qa({\"query\": query})\n",
    "    return result\n",
    "\n",
    "with gr.Blocks() as tcw_bot:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"Enter question and press enter\", show_label=False)\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "    \n",
    "    def bot(history):\n",
    "        response = qa_query(history[-1][0])\n",
    "        print(response)\n",
    "        response_result = response[\"result\"]\n",
    "        metadata = response[\"source_documents\"]\n",
    "        history[-1][1] = response_result\n",
    "\n",
    "        return history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "\n",
    "tcw_bot.launch(share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
